"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[2125],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>g});var a=n(67294);function l(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){l(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,l=function(e,t){if(null==e)return{};var n,a,l={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(l[n]=e[n]);return l}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(l[n]=e[n])}return l}var s=a.createContext({}),d=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=d(e.components);return a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,l=e.mdxType,r=e.originalType,s=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),m=d(n),g=l,f=m["".concat(s,".").concat(g)]||m[g]||u[g]||r;return n?a.createElement(f,i(i({ref:t},p),{},{components:n})):a.createElement(f,i({ref:t},p))}));function g(e,t){var n=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var r=n.length,i=new Array(r);i[0]=m;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:l,i[1]=o;for(var d=2;d<r;d++)i[d]=n[d];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},18679:(e,t,n)=>{n.d(t,{Z:()=>i});var a=n(67294),l=n(86010);const r="tabItem_Ymn6";function i(e){let{children:t,hidden:n,className:i}=e;return a.createElement("div",{role:"tabpanel",className:(0,l.Z)(r,i),hidden:n},t)}},34259:(e,t,n)=>{n.d(t,{Z:()=>g});var a=n(87462),l=n(67294),r=n(86010),i=n(51048),o=n(33609),s=n(1943),d=n(72957);const p="tabList__CuJ",u="tabItem_LNqP";function m(e){var t,n;const{lazy:i,block:m,defaultValue:g,values:f,groupId:c,className:k}=e,h=l.Children.map(e.children,(e=>{if((0,l.isValidElement)(e)&&"value"in e.props)return e;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')})),N=null!=f?f:h.map((e=>{let{props:{value:t,label:n,attributes:a}}=e;return{value:t,label:n,attributes:a}})),b=(0,o.l)(N,((e,t)=>e.value===t.value));if(b.length>0)throw new Error('Docusaurus error: Duplicate values "'+b.map((e=>e.value)).join(", ")+'" found in <Tabs>. Every value needs to be unique.');const _=null===g?g:null!=(t=null!=g?g:null==(n=h.find((e=>e.props.default)))?void 0:n.props.value)?t:h[0].props.value;if(null!==_&&!N.some((e=>e.value===_)))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+_+'" but none of its children has the corresponding value. Available values are: '+N.map((e=>e.value)).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");const{tabGroupChoices:y,setTabGroupChoices:v}=(0,s.U)(),[w,T]=(0,l.useState)(_),C=[],{blockElementScrollPositionUntilNextRender:x}=(0,d.o5)();if(null!=c){const e=y[c];null!=e&&e!==w&&N.some((t=>t.value===e))&&T(e)}const S=e=>{const t=e.currentTarget,n=C.indexOf(t),a=N[n].value;a!==w&&(x(t),T(a),null!=c&&v(c,String(a)))},q=e=>{var t;let n=null;switch(e.key){case"ArrowRight":{var a;const t=C.indexOf(e.currentTarget)+1;n=null!=(a=C[t])?a:C[0];break}case"ArrowLeft":{var l;const t=C.indexOf(e.currentTarget)-1;n=null!=(l=C[t])?l:C[C.length-1];break}}null==(t=n)||t.focus()};return l.createElement("div",{className:(0,r.Z)("tabs-container",p)},l.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.Z)("tabs",{"tabs--block":m},k)},N.map((e=>{let{value:t,label:n,attributes:i}=e;return l.createElement("li",(0,a.Z)({role:"tab",tabIndex:w===t?0:-1,"aria-selected":w===t,key:t,ref:e=>C.push(e),onKeyDown:q,onFocus:S,onClick:S},i,{className:(0,r.Z)("tabs__item",u,null==i?void 0:i.className,{"tabs__item--active":w===t})}),null!=n?n:t)}))),i?(0,l.cloneElement)(h.filter((e=>e.props.value===w))[0],{className:"margin-top--md"}):l.createElement("div",{className:"margin-top--md"},h.map(((e,t)=>(0,l.cloneElement)(e,{key:t,hidden:e.props.value!==w})))))}function g(e){const t=(0,i.Z)();return l.createElement(m,(0,a.Z)({key:String(t)},e))}},35503:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>g,frontMatter:()=>o,metadata:()=>d,toc:()=>u});var a=n(87462),l=(n(67294),n(3905)),r=n(34259),i=n(18679);const o={title:"Redshift",slug:"/generated/ingestion/sources/redshift",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/ingestion/sources/redshift.md"},s="Redshift",d={unversionedId:"docs/generated/ingestion/sources/redshift",id:"docs/generated/ingestion/sources/redshift",title:"Redshift",description:"There are 2 sources that provide integration with Redshift",source:"@site/genDocs/docs/generated/ingestion/sources/redshift.md",sourceDirName:"docs/generated/ingestion/sources",slug:"/generated/ingestion/sources/redshift",permalink:"/docs/generated/ingestion/sources/redshift",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/generated/ingestion/sources/redshift.md",tags:[],version:"current",frontMatter:{title:"Redshift",slug:"/generated/ingestion/sources/redshift",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/ingestion/sources/redshift.md"},sidebar:"overviewSidebar",previous:{title:"Redash",permalink:"/docs/generated/ingestion/sources/redash"},next:{title:"S3 Data Lake",permalink:"/docs/generated/ingestion/sources/s3"}},p={},u=[{value:"Prerequisites",id:"prerequisites",level:3},{value:"Lineage",id:"lineage",level:3},{value:"stl_scan_based",id:"stl_scan_based",level:4},{value:"sql_based",id:"sql_based",level:4},{value:"mixed",id:"mixed",level:4},{value:"Module <code>redshift</code>",id:"module-redshift",level:2},{value:"Important Capabilities",id:"important-capabilities",level:3},{value:"Prerequisites",id:"prerequisites-1",level:3},{value:"Lineage",id:"lineage-1",level:3},{value:"stl_scan_based",id:"stl_scan_based-1",level:4},{value:"sql_based",id:"sql_based-1",level:4},{value:"mixed",id:"mixed-1",level:4},{value:"CLI based Ingestion",id:"cli-based-ingestion",level:3},{value:"Install the Plugin",id:"install-the-plugin",level:4},{value:"Starter Recipe",id:"starter-recipe",level:3},{value:"Config Details",id:"config-details",level:3},{value:"Code Coordinates",id:"code-coordinates",level:3},{value:"Module <code>redshift-usage</code>",id:"module-redshift-usage",level:2},{value:"Important Capabilities",id:"important-capabilities-1",level:3},{value:"CLI based Ingestion",id:"cli-based-ingestion-1",level:3},{value:"Install the Plugin",id:"install-the-plugin-1",level:4},{value:"Starter Recipe",id:"starter-recipe-1",level:3},{value:"Config Details",id:"config-details-1",level:3},{value:"Code Coordinates",id:"code-coordinates-1",level:3},{value:"Questions",id:"questions",level:2}],m={toc:u};function g(e){let{components:t,...n}=e;return(0,l.kt)("wrapper",(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"redshift"},"Redshift"),(0,l.kt)("p",null,"There are 2 sources that provide integration with Redshift"),(0,l.kt)("table",null,(0,l.kt)("tr",null,(0,l.kt)("td",null,"Source Module"),(0,l.kt)("td",null,"Documentation")),(0,l.kt)("tr",null,(0,l.kt)("td",null,(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"redshift"))),(0,l.kt)("td",null,(0,l.kt)("p",null,"This plugin extracts the following:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Metadata for databases, schemas, views and tables"),(0,l.kt)("li",{parentName:"ul"},"Column types associated with each table"),(0,l.kt)("li",{parentName:"ul"},"Also supports PostGIS extensions"),(0,l.kt)("li",{parentName:"ul"},"Table, row, and column statistics via optional SQL profiling"),(0,l.kt)("li",{parentName:"ul"},"Table lineage")),(0,l.kt)("admonition",{type:"tip"},(0,l.kt)("p",{parentName:"admonition"},"You can also get fine-grained usage statistics for Redshift using the ",(0,l.kt)("inlineCode",{parentName:"p"},"redshift-usage")," source described below.")),(0,l.kt)("h3",{id:"prerequisites"},"Prerequisites"),(0,l.kt)("p",null,"This source needs to access system tables that require extra permissions.\nTo grant these permissions, please alter your datahub Redshift user the following way:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER USER datahub_user WITH SYSLOG ACCESS UNRESTRICTED;\nGRANT SELECT ON pg_catalog.svv_table_info to datahub_user;\nGRANT SELECT ON pg_catalog.svl_user_info to datahub_user;\n")),(0,l.kt)("admonition",{type:"note"},(0,l.kt)("p",{parentName:"admonition"},"Giving a user unrestricted access to system tables gives the user visibility to data generated by other users. For example, STL_QUERY and STL_QUERYTEXT contain the full text of INSERT, UPDATE, and DELETE statements.")),(0,l.kt)("h3",{id:"lineage"},"Lineage"),(0,l.kt)("p",null,"There are multiple lineage collector implementations as Redshift does not support table lineage out of the box."),(0,l.kt)("h4",{id:"stl_scan_based"},"stl_scan_based"),(0,l.kt)("p",null,"The stl_scan based collector uses Redshift's ",(0,l.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/redshift/latest/dg/r_STL_INSERT.html"},"stl_insert")," and ",(0,l.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/redshift/latest/dg/r_STL_SCAN.html"},"stl_scan")," system tables to\ndiscover lineage between tables.\nPros:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Fast"),(0,l.kt)("li",{parentName:"ul"},"Reliable")),(0,l.kt)("p",null,"Cons:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Does not work with Spectrum/external tables because those scans do not show up in stl_scan table."),(0,l.kt)("li",{parentName:"ul"},"If a table is depending on a view then the view won't be listed as dependency. Instead the table will be connected with the view's dependencies.")),(0,l.kt)("h4",{id:"sql_based"},"sql_based"),(0,l.kt)("p",null,"The sql_based based collector uses Redshift's ",(0,l.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/redshift/latest/dg/r_STL_INSERT.html"},"stl_insert")," to discover all the insert queries\nand uses sql parsing to discover the dependecies."),(0,l.kt)("p",null,"Pros:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Works with Spectrum tables"),(0,l.kt)("li",{parentName:"ul"},"Views are connected properly if a table depends on it")),(0,l.kt)("p",null,"Cons:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Slow."),(0,l.kt)("li",{parentName:"ul"},"Less reliable as the query parser can fail on certain queries")),(0,l.kt)("h4",{id:"mixed"},"mixed"),(0,l.kt)("p",null,"Using both collector above and first applying the sql based and then the stl_scan based one."),(0,l.kt)("p",null,"Pros:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Works with Spectrum tables"),(0,l.kt)("li",{parentName:"ul"},"Views are connected properly if a table depends on it"),(0,l.kt)("li",{parentName:"ul"},"A bit more reliable than the sql_based one only")),(0,l.kt)("p",null,"Cons:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Slow"),(0,l.kt)("li",{parentName:"ul"},"May be incorrect at times as the query parser can fail on certain queries")),(0,l.kt)("admonition",{type:"note"},(0,l.kt)("p",{parentName:"admonition"},"The redshift stl redshift tables which are used for getting data lineage only retain approximately two to five days of log history. This means you cannot extract lineage from queries issued outside that window.")),(0,l.kt)("p",null," ",(0,l.kt)("a",{parentName:"p",href:"#module-redshift"},"Read more...")))),(0,l.kt)("tr",null,(0,l.kt)("td",null,(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"redshift-usage"))),(0,l.kt)("td",null,(0,l.kt)("p",null,"This plugin extracts usage statistics for datasets in Amazon Redshift."),(0,l.kt)("p",null,"Note: Usage information is computed by querying the following system tables -"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"stl_scan"),(0,l.kt)("li",{parentName:"ol"},"svv_table_info"),(0,l.kt)("li",{parentName:"ol"},"stl_query"),(0,l.kt)("li",{parentName:"ol"},"svl_user_info")),(0,l.kt)("p",null,"To grant access this plugin for all system tables, please alter your datahub Redshift user the following way:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER USER datahub_user WITH SYSLOG ACCESS UNRESTRICTED;\n")),(0,l.kt)("p",null,"This plugin has the below functionalities -"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"For a specific dataset this plugin ingests the following statistics -",(0,l.kt)("ol",{parentName:"li"},(0,l.kt)("li",{parentName:"ol"},"top n queries."),(0,l.kt)("li",{parentName:"ol"},"top users."),(0,l.kt)("li",{parentName:"ol"},"usage of each column in the dataset."))),(0,l.kt)("li",{parentName:"ol"},"Aggregation of these statistics into buckets, by day or hour granularity.")),(0,l.kt)("admonition",{type:"note"},(0,l.kt)("p",{parentName:"admonition"},"This source only does usage statistics. To get the tables, views, and schemas in your Redshift warehouse, ingest using the ",(0,l.kt)("inlineCode",{parentName:"p"},"redshift")," source described above.")),(0,l.kt)("admonition",{type:"note"},(0,l.kt)("p",{parentName:"admonition"},"Redshift system tables have some latency in getting data from queries. In addition, these tables only maintain logs for 2-5 days. You can find more information from the official documentation ",(0,l.kt)("a",{parentName:"p",href:"https://aws.amazon.com/premiumsupport/knowledge-center/logs-redshift-database-cluster/"},"here"),".")),(0,l.kt)("p",null," ",(0,l.kt)("a",{parentName:"p",href:"#module-redshift-usage"},"Read more..."))))),(0,l.kt)("p",null,"To get all metadata from Redshift you need to use two plugins ",(0,l.kt)("inlineCode",{parentName:"p"},"redshift")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"redshift-usage"),". Both of them are described in this page. These will require 2 separate recipes. We understand this is not ideal and we plan to make this easier in the future."),(0,l.kt)("h2",{id:"module-redshift"},"Module ",(0,l.kt)("inlineCode",{parentName:"h2"},"redshift")),(0,l.kt)("p",null,(0,l.kt)("img",{parentName:"p",src:"https://img.shields.io/badge/support%20status-certified-brightgreen",alt:"Certified"})),(0,l.kt)("h3",{id:"important-capabilities"},"Important Capabilities"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Capability"),(0,l.kt)("th",{parentName:"tr",align:null},"Status"),(0,l.kt)("th",{parentName:"tr",align:null},"Notes"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("a",{parentName:"td",href:"/docs/metadata-ingestion/docs/dev_guides/sql_profiles"},"Data Profiling")),(0,l.kt)("td",{parentName:"tr",align:null},"\u2705"),(0,l.kt)("td",{parentName:"tr",align:null},"Optionally enabled via configuration")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"Dataset Usage"),(0,l.kt)("td",{parentName:"tr",align:null},"\u274c"),(0,l.kt)("td",{parentName:"tr",align:null},"Not provided by this module, use ",(0,l.kt)("inlineCode",{parentName:"td"},"redshift-usage")," for that.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"Descriptions"),(0,l.kt)("td",{parentName:"tr",align:null},"\u2705"),(0,l.kt)("td",{parentName:"tr",align:null},"Enabled by default")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("a",{parentName:"td",href:"/docs/metadata-ingestion/docs/dev_guides/stateful#stale-entity-removal"},"Detect Deleted Entities")),(0,l.kt)("td",{parentName:"tr",align:null},"\u2705"),(0,l.kt)("td",{parentName:"tr",align:null},"Enabled via stateful ingestion")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("a",{parentName:"td",href:"/docs/domains"},"Domains")),(0,l.kt)("td",{parentName:"tr",align:null},"\u2705"),(0,l.kt)("td",{parentName:"tr",align:null},"Supported via the ",(0,l.kt)("inlineCode",{parentName:"td"},"domain")," config field")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("a",{parentName:"td",href:"/docs/platform-instances"},"Platform Instance")),(0,l.kt)("td",{parentName:"tr",align:null},"\u2705"),(0,l.kt)("td",{parentName:"tr",align:null},"Enabled by default")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"Table-Level Lineage"),(0,l.kt)("td",{parentName:"tr",align:null},"\u2705"),(0,l.kt)("td",{parentName:"tr",align:null},"Optionally enabled via configuration")))),(0,l.kt)("p",null,"This plugin extracts the following:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Metadata for databases, schemas, views and tables"),(0,l.kt)("li",{parentName:"ul"},"Column types associated with each table"),(0,l.kt)("li",{parentName:"ul"},"Also supports PostGIS extensions"),(0,l.kt)("li",{parentName:"ul"},"Table, row, and column statistics via optional SQL profiling"),(0,l.kt)("li",{parentName:"ul"},"Table lineage")),(0,l.kt)("admonition",{type:"tip"},(0,l.kt)("p",{parentName:"admonition"},"You can also get fine-grained usage statistics for Redshift using the ",(0,l.kt)("inlineCode",{parentName:"p"},"redshift-usage")," source described below.")),(0,l.kt)("h3",{id:"prerequisites-1"},"Prerequisites"),(0,l.kt)("p",null,"This source needs to access system tables that require extra permissions.\nTo grant these permissions, please alter your datahub Redshift user the following way:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER USER datahub_user WITH SYSLOG ACCESS UNRESTRICTED;\nGRANT SELECT ON pg_catalog.svv_table_info to datahub_user;\nGRANT SELECT ON pg_catalog.svl_user_info to datahub_user;\n")),(0,l.kt)("admonition",{type:"note"},(0,l.kt)("p",{parentName:"admonition"},"Giving a user unrestricted access to system tables gives the user visibility to data generated by other users. For example, STL_QUERY and STL_QUERYTEXT contain the full text of INSERT, UPDATE, and DELETE statements.")),(0,l.kt)("h3",{id:"lineage-1"},"Lineage"),(0,l.kt)("p",null,"There are multiple lineage collector implementations as Redshift does not support table lineage out of the box."),(0,l.kt)("h4",{id:"stl_scan_based-1"},"stl_scan_based"),(0,l.kt)("p",null,"The stl_scan based collector uses Redshift's ",(0,l.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/redshift/latest/dg/r_STL_INSERT.html"},"stl_insert")," and ",(0,l.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/redshift/latest/dg/r_STL_SCAN.html"},"stl_scan")," system tables to\ndiscover lineage between tables.\nPros:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Fast"),(0,l.kt)("li",{parentName:"ul"},"Reliable")),(0,l.kt)("p",null,"Cons:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Does not work with Spectrum/external tables because those scans do not show up in stl_scan table."),(0,l.kt)("li",{parentName:"ul"},"If a table is depending on a view then the view won't be listed as dependency. Instead the table will be connected with the view's dependencies.")),(0,l.kt)("h4",{id:"sql_based-1"},"sql_based"),(0,l.kt)("p",null,"The sql_based based collector uses Redshift's ",(0,l.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/redshift/latest/dg/r_STL_INSERT.html"},"stl_insert")," to discover all the insert queries\nand uses sql parsing to discover the dependecies."),(0,l.kt)("p",null,"Pros:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Works with Spectrum tables"),(0,l.kt)("li",{parentName:"ul"},"Views are connected properly if a table depends on it")),(0,l.kt)("p",null,"Cons:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Slow."),(0,l.kt)("li",{parentName:"ul"},"Less reliable as the query parser can fail on certain queries")),(0,l.kt)("h4",{id:"mixed-1"},"mixed"),(0,l.kt)("p",null,"Using both collector above and first applying the sql based and then the stl_scan based one."),(0,l.kt)("p",null,"Pros:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Works with Spectrum tables"),(0,l.kt)("li",{parentName:"ul"},"Views are connected properly if a table depends on it"),(0,l.kt)("li",{parentName:"ul"},"A bit more reliable than the sql_based one only")),(0,l.kt)("p",null,"Cons:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Slow"),(0,l.kt)("li",{parentName:"ul"},"May be incorrect at times as the query parser can fail on certain queries")),(0,l.kt)("admonition",{type:"note"},(0,l.kt)("p",{parentName:"admonition"},"The redshift stl redshift tables which are used for getting data lineage only retain approximately two to five days of log history. This means you cannot extract lineage from queries issued outside that window.")),(0,l.kt)("h3",{id:"cli-based-ingestion"},"CLI based Ingestion"),(0,l.kt)("h4",{id:"install-the-plugin"},"Install the Plugin"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell"},"pip install 'acryl-datahub[redshift]'\n")),(0,l.kt)("h3",{id:"starter-recipe"},"Starter Recipe"),(0,l.kt)("p",null,"Check out the following recipe to get started with ingestion! See ",(0,l.kt)("a",{parentName:"p",href:"#config-details"},"below")," for full configuration options."),(0,l.kt)("p",null,"For general pointers on writing and running a recipe, see our ",(0,l.kt)("a",{parentName:"p",href:"/docs/metadata-ingestion#recipes"},"main recipe guide"),"."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},'source:\n  type: redshift\n  config:\n    # Coordinates\n    host_port: example.something.us-west-2.redshift.amazonaws.com:5439\n    database: DemoDatabase\n\n    # Credentials\n    username: user\n    password: pass\n\n    # Options\n    options:\n      # driver_option: some-option\n\n    include_views: True # whether to include views, defaults to True\n    include_tables: True # whether to include views, defaults to True\n\nsink:\n  # sink configs\n\n#------------------------------------------------------------------------------\n# Extra options when running Redshift behind a proxy</summary>\n# This requires you to have already installed the Microsoft ODBC Driver for SQL Server.\n# See https://docs.microsoft.com/en-us/sql/connect/python/pyodbc/step-1-configure-development-environment-for-pyodbc-python-development?view=sql-server-ver15\n#------------------------------------------------------------------------------\n\nsource:\n  type: redshift\n  config:\n    host_port: my-proxy-hostname:5439\n\n    options:\n      connect_args:\n        sslmode: "prefer" # or "require" or "verify-ca"\n        sslrootcert: ~ # needed to unpin the AWS Redshift certificate\n\nsink:\n  # sink configs\n\n')),(0,l.kt)("h3",{id:"config-details"},"Config Details"),(0,l.kt)(r.Z,{mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"options",label:"Options",default:!0,mdxType:"TabItem"},(0,l.kt)("p",null,"Note that a ",(0,l.kt)("inlineCode",{parentName:"p"},".")," is used to denote nested fields in the YAML recipe."),(0,l.kt)("details",{open:!0},(0,l.kt)("summary",null,"View All Configuration Options"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Field"),(0,l.kt)("th",{parentName:"tr",align:null},"Required"),(0,l.kt)("th",{parentName:"tr",align:null},"Type"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Default"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"env"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"The environment that all assets produced by this connector belong to"),(0,l.kt)("td",{parentName:"tr",align:null},"PROD")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"platform_instance_map"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Dict","[str,string]"),(0,l.kt)("td",{parentName:"tr",align:null},"A holder for platform -> platform_instance mappings to generate correct dataset urns"),(0,l.kt)("td",{parentName:"tr",align:null})),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"bucket_duration"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"enum(BucketDuration)"),(0,l.kt)("td",{parentName:"tr",align:null},"Size of the time window to aggregate usage stats.. Allowed symbols are DAY, HOUR"),(0,l.kt)("td",{parentName:"tr",align:null},"DAY")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"end_time"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"Latest date of usage to consider. Default: Current time in UTC"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"start_time"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"Earliest date of usage to consider. Default: Last full day in UTC (or hour, depending on ",(0,l.kt)("inlineCode",{parentName:"td"},"bucket_duration"),")"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"platform"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"The platform that this source connects to"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"platform_instance"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"The instance of the platform that all assets produced by this recipe belong to"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"options"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Dict"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"{}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"include_views"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether views should be ingested."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"include_tables"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether tables should be ingested."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"username"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"username"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"password"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"password"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"host_port"),(0,l.kt)("td",{parentName:"tr",align:null},"\u2705"),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"host URL"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"database"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"database (catalog)"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"database_alias"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"Alias to apply to database when ingesting."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"sqlalchemy_uri"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"URI of database to connect to. See ",(0,l.kt)("a",{parentName:"td",href:"https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls"},"https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls"),". Takes precedence over other connection parameters."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"default_schema"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"The default schema to use if the sql parser fails to parse the schema with ",(0,l.kt)("inlineCode",{parentName:"td"},"sql_based")," lineage collector"),(0,l.kt)("td",{parentName:"tr",align:null},"public")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"include_table_lineage"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether table lineage should be ingested."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"include_copy_lineage"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether lineage should be collected from copy commands"),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"capture_lineage_query_parser_failures"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to capture lineage query parser errors with dataset properties for debuggings"),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"table_lineage_mode"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"enum(LineageMode)"),(0,l.kt)("td",{parentName:"tr",align:null},"Which table lineage collector mode to use. Available modes are: ","[stl_scan_based, sql_based, mixed]"),(0,l.kt)("td",{parentName:"tr",align:null},"stl_scan_based")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"s3_lineage_config"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"S3LineageProviderConfig (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null},"Common config for S3 lineage generation"),(0,l.kt)("td",{parentName:"tr",align:null})),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"s3_lineage_config.path_specs"),(0,l.kt)("td",{parentName:"tr",align:null},"\u2753 (required if s3_lineage_config is set)"),(0,l.kt)("td",{parentName:"tr",align:null},"Array of object"),(0,l.kt)("td",{parentName:"tr",align:null},"List of PathSpec. See below the details about PathSpec"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"SQLAlchemyStatefulIngestionConfig (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null})),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.enabled"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"The type of the ingestion state provider registered with datahub."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.max_checkpoint_state_size"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"The maximum size of the checkpoint state in bytes. Default is 16MB"),(0,l.kt)("td",{parentName:"tr",align:null},"16777216")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.state_provider"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"DynamicTypedStateProviderConfig (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null},"The ingestion state provider configuration."),(0,l.kt)("td",{parentName:"tr",align:null})),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.state_provider.type"),(0,l.kt)("td",{parentName:"tr",align:null},"\u2753 (required if stateful_ingestion.state_provider is set)"),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"The type of the state provider to use. For DataHub use ",(0,l.kt)("inlineCode",{parentName:"td"},"datahub")),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.state_provider.config"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Generic dict"),(0,l.kt)("td",{parentName:"tr",align:null},"The configuration required for initializing the state provider. Default: The datahub_api config if set at pipeline level. Otherwise, the default DatahubClientConfig. See the defaults (",(0,l.kt)("a",{parentName:"td",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/graph/client.py#L19"},"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/graph/client.py#L19"),")."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.ignore_old_state"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"If set to True, ignores the previous checkpoint state."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.ignore_new_state"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"If set to True, ignores the current checkpoint state."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.remove_stale_metadata"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Soft-deletes the entities of type  in the last successful run but missing in the current run with stateful_ingestion enabled."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.fail_safe_threshold"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"number"),(0,l.kt)("td",{parentName:"tr",align:null},"Prevents large amount of soft deletes & the state from committing from accidental changes to the source configuration if the relative change percent in entities compared to the previous state is above the 'fail_safe_threshold'."),(0,l.kt)("td",{parentName:"tr",align:null},"20.0")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"schema_pattern"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"AllowDenyPattern (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"{'allow': ","['.*']",", 'deny': ","['information_schema']",", 'ignoreCase': True}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"schema_pattern.allow"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to include in ingestion"),(0,l.kt)("td",{parentName:"tr",align:null},"['.*']")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"schema_pattern.deny"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to exclude from ingestion."),(0,l.kt)("td",{parentName:"tr",align:null},"[]")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"schema_pattern.ignoreCase"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to ignore case sensitivity during pattern matching."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"table_pattern"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"AllowDenyPattern (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null},"Regex patterns for tables to filter in ingestion. Specify regex to match the entire table name in database.schema.table format. e.g. to match all tables starting with customer in Customer database and public schema, use the regex 'Customer.public.customer.*'"),(0,l.kt)("td",{parentName:"tr",align:null},"{'allow': ","['.*']",", 'deny': [], 'ignoreCase': True}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"table_pattern.allow"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to include in ingestion"),(0,l.kt)("td",{parentName:"tr",align:null},"['.*']")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"table_pattern.deny"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to exclude from ingestion."),(0,l.kt)("td",{parentName:"tr",align:null},"[]")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"table_pattern.ignoreCase"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to ignore case sensitivity during pattern matching."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"view_pattern"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"AllowDenyPattern (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null},"Regex patterns for views to filter in ingestion. Note: Defaults to table_pattern if not specified. Specify regex to match the entire view name in database.schema.view format. e.g. to match all views starting with customer in Customer database and public schema, use the regex 'Customer.public.customer.*'"),(0,l.kt)("td",{parentName:"tr",align:null},"{'allow': ","['.*']",", 'deny': [], 'ignoreCase': True}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"view_pattern.allow"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to include in ingestion"),(0,l.kt)("td",{parentName:"tr",align:null},"['.*']")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"view_pattern.deny"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to exclude from ingestion."),(0,l.kt)("td",{parentName:"tr",align:null},"[]")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"view_pattern.ignoreCase"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to ignore case sensitivity during pattern matching."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profile_pattern"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"AllowDenyPattern (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null},"Regex patterns to filter tables for profiling during ingestion. Allowed by the ",(0,l.kt)("inlineCode",{parentName:"td"},"table_pattern"),"."),(0,l.kt)("td",{parentName:"tr",align:null},"{'allow': ","['.*']",", 'deny': [], 'ignoreCase': True}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profile_pattern.allow"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to include in ingestion"),(0,l.kt)("td",{parentName:"tr",align:null},"['.*']")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profile_pattern.deny"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to exclude from ingestion."),(0,l.kt)("td",{parentName:"tr",align:null},"[]")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profile_pattern.ignoreCase"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to ignore case sensitivity during pattern matching."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"domain"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Dict","[str, AllowDenyPattern]"),(0,l.kt)("td",{parentName:"tr",align:null},"Attach domains to databases, schemas or tables during ingestion using regex patterns. Domain key can be a guid like ",(0,l.kt)("em",{parentName:"td"},"urn:li:domain:ec428203-ce86-4db3-985d-5a8ee6df32ba"),' or a string like "Marketing".) If you provide strings, then datahub will attempt to resolve this name to a guid, and will error out if this fails. There can be multiple domain keys specified.'),(0,l.kt)("td",{parentName:"tr",align:null},"{}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"domain.",(0,l.kt)("inlineCode",{parentName:"td"},"key"),".allow"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to include in ingestion"),(0,l.kt)("td",{parentName:"tr",align:null},"['.*']")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"domain.",(0,l.kt)("inlineCode",{parentName:"td"},"key"),".deny"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to exclude from ingestion."),(0,l.kt)("td",{parentName:"tr",align:null},"[]")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"domain.",(0,l.kt)("inlineCode",{parentName:"td"},"key"),".ignoreCase"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to ignore case sensitivity during pattern matching."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"GEProfilingConfig (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"{'enabled': False, 'limit': None, 'offset': None, 'report_dropped_profiles': False, 'turn_off_expensive_profiling_metrics': False, 'profile_table_level_only': False, 'include_field_null_count': True, 'include_field_min_value': True, 'include_field_max_value': True, 'include_field_mean_value': True, 'include_field_median_value': True, 'include_field_stddev_value': True, 'include_field_quantiles': False, 'include_field_distinct_value_frequencies': False, 'include_field_histogram': False, 'include_field_sample_values': True, 'max_number_of_fields_to_profile': None, 'profile_if_updated_since_days': 1, 'profile_table_size_limit': 1, 'profile_table_row_limit': 50000, 'max_workers': 10, 'query_combiner_enabled': True, 'catch_exceptions': True, 'partition_profiling_enabled': True, 'bigquery_temp_table_schema': None, 'partition_datetime': None}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.enabled"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether profiling should be done."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.limit"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"Max number of documents to profile. By default, profiles all documents."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.offset"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"Offset in documents to profile. By default, uses no offset."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.report_dropped_profiles"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to report datasets or dataset columns which were not profiled. Set to ",(0,l.kt)("inlineCode",{parentName:"td"},"True")," for debugging purposes."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.turn_off_expensive_profiling_metrics"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to turn off expensive profiling or not. This turns off profiling for quantiles, distinct_value_frequencies, histogram & sample_values. This also limits maximum number of fields being profiled to 10."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.profile_table_level_only"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to perform profiling at table-level only, or include column-level profiling as well."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_null_count"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the number of nulls for each column."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_min_value"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the min value of numeric columns."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_max_value"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the max value of numeric columns."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_mean_value"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the mean value of numeric columns."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_median_value"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the median value of numeric columns."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_stddev_value"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the standard deviation of numeric columns."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_quantiles"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the quantiles of numeric columns."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_distinct_value_frequencies"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for distinct value frequencies."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_histogram"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the histogram for numeric fields."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_sample_values"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the sample values for all columns."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.max_number_of_fields_to_profile"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"A positive integer that specifies the maximum number of columns to profile for any table. ",(0,l.kt)("inlineCode",{parentName:"td"},"None")," implies all columns. The cost of profiling goes up significantly as the number of columns to profile goes up."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.profile_if_updated_since_days"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"number"),(0,l.kt)("td",{parentName:"tr",align:null},"Profile table only if it has been updated since these many number of days. If set to ",(0,l.kt)("inlineCode",{parentName:"td"},"null"),", no constraint of last modified time for tables to profile. Supported only in ",(0,l.kt)("inlineCode",{parentName:"td"},"snowflake"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"snowflake-beta")," and ",(0,l.kt)("inlineCode",{parentName:"td"},"BigQuery"),"."),(0,l.kt)("td",{parentName:"tr",align:null},"1")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.profile_table_size_limit"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"Profile tables only if their size is less then specified GBs. If set to ",(0,l.kt)("inlineCode",{parentName:"td"},"null"),", no limit on the size of tables to profile. Supported only in ",(0,l.kt)("inlineCode",{parentName:"td"},"snowflake-beta")," and ",(0,l.kt)("inlineCode",{parentName:"td"},"BigQuery")),(0,l.kt)("td",{parentName:"tr",align:null},"1")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.profile_table_row_limit"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"Profile tables only if their row count is less then specified count. If set to ",(0,l.kt)("inlineCode",{parentName:"td"},"null"),", no limit on the row count of tables to profile. Supported only in ",(0,l.kt)("inlineCode",{parentName:"td"},"snowflake-beta")," and ",(0,l.kt)("inlineCode",{parentName:"td"},"BigQuery")),(0,l.kt)("td",{parentName:"tr",align:null},"50000")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.max_workers"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"Number of worker threads to use for profiling. Set to 1 to disable."),(0,l.kt)("td",{parentName:"tr",align:null},"10")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.query_combiner_enabled"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("em",{parentName:"td"},"This feature is still experimental and can be disabled if it causes issues.")," Reduces the total number of queries issued and speeds up profiling by dynamically combining SQL queries where possible."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.catch_exceptions"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.partition_profiling_enabled"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.bigquery_temp_table_schema"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"On bigquery for profiling partitioned tables needs to create temporary views. You have to define a dataset where these will be created. Views will be cleaned up after profiler runs. (Great expectation tech details about this (",(0,l.kt)("a",{parentName:"td",href:"https://legacy.docs.greatexpectations.io/en/0.9.0/reference/integrations/bigquery.html#custom-queries-with-sql-datasource"},"https://legacy.docs.greatexpectations.io/en/0.9.0/reference/integrations/bigquery.html#custom-queries-with-sql-datasource"),")."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.partition_datetime"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"For partitioned datasets profile only the partition which matches the datetime or profile the latest one if not set. Only Bigquery supports this."),(0,l.kt)("td",{parentName:"tr",align:null},"None")))))),(0,l.kt)(i.Z,{value:"schema",label:"Schema",mdxType:"TabItem"},(0,l.kt)("p",null,"The ",(0,l.kt)("a",{parentName:"p",href:"https://json-schema.org/"},"JSONSchema")," for this configuration is inlined below."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-javascript"},'{\n  "title": "RedshiftConfig",\n  "description": "Base configuration class for stateful ingestion for source configs to inherit from.",\n  "type": "object",\n  "properties": {\n    "s3_lineage_config": {\n      "title": "S3 Lineage Config",\n      "description": "Common config for S3 lineage generation",\n      "allOf": [\n        {\n          "$ref": "#/definitions/S3LineageProviderConfig"\n        }\n      ]\n    },\n    "env": {\n      "title": "Env",\n      "description": "The environment that all assets produced by this connector belong to",\n      "default": "PROD",\n      "type": "string"\n    },\n    "platform_instance_map": {\n      "title": "Platform Instance Map",\n      "description": "A holder for platform -> platform_instance mappings to generate correct dataset urns",\n      "type": "object",\n      "additionalProperties": {\n        "type": "string"\n      }\n    },\n    "bucket_duration": {\n      "description": "Size of the time window to aggregate usage stats.",\n      "default": "DAY",\n      "allOf": [\n        {\n          "$ref": "#/definitions/BucketDuration"\n        }\n      ]\n    },\n    "end_time": {\n      "title": "End Time",\n      "description": "Latest date of usage to consider. Default: Current time in UTC",\n      "type": "string",\n      "format": "date-time"\n    },\n    "start_time": {\n      "title": "Start Time",\n      "description": "Earliest date of usage to consider. Default: Last full day in UTC (or hour, depending on `bucket_duration`)",\n      "type": "string",\n      "format": "date-time"\n    },\n    "platform": {\n      "title": "Platform",\n      "description": "The platform that this source connects to",\n      "type": "string"\n    },\n    "platform_instance": {\n      "title": "Platform Instance",\n      "description": "The instance of the platform that all assets produced by this recipe belong to",\n      "type": "string"\n    },\n    "stateful_ingestion": {\n      "$ref": "#/definitions/SQLAlchemyStatefulIngestionConfig"\n    },\n    "options": {\n      "title": "Options",\n      "default": {},\n      "type": "object"\n    },\n    "schema_pattern": {\n      "title": "Schema Pattern",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [\n          "information_schema"\n        ],\n        "ignoreCase": true\n      },\n      "allOf": [\n        {\n          "$ref": "#/definitions/AllowDenyPattern"\n        }\n      ]\n    },\n    "table_pattern": {\n      "title": "Table Pattern",\n      "description": "Regex patterns for tables to filter in ingestion. Specify regex to match the entire table name in database.schema.table format. e.g. to match all tables starting with customer in Customer database and public schema, use the regex \'Customer.public.customer.*\'",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "allOf": [\n        {\n          "$ref": "#/definitions/AllowDenyPattern"\n        }\n      ]\n    },\n    "view_pattern": {\n      "title": "View Pattern",\n      "description": "Regex patterns for views to filter in ingestion. Note: Defaults to table_pattern if not specified. Specify regex to match the entire view name in database.schema.view format. e.g. to match all views starting with customer in Customer database and public schema, use the regex \'Customer.public.customer.*\'",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "allOf": [\n        {\n          "$ref": "#/definitions/AllowDenyPattern"\n        }\n      ]\n    },\n    "profile_pattern": {\n      "title": "Profile Pattern",\n      "description": "Regex patterns to filter tables for profiling during ingestion. Allowed by the `table_pattern`.",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "allOf": [\n        {\n          "$ref": "#/definitions/AllowDenyPattern"\n        }\n      ]\n    },\n    "domain": {\n      "title": "Domain",\n      "description": "Attach domains to databases, schemas or tables during ingestion using regex patterns. Domain key can be a guid like *urn:li:domain:ec428203-ce86-4db3-985d-5a8ee6df32ba* or a string like \\"Marketing\\".) If you provide strings, then datahub will attempt to resolve this name to a guid, and will error out if this fails. There can be multiple domain keys specified.",\n      "default": {},\n      "type": "object",\n      "additionalProperties": {\n        "$ref": "#/definitions/AllowDenyPattern"\n      }\n    },\n    "include_views": {\n      "title": "Include Views",\n      "description": "Whether views should be ingested.",\n      "default": true,\n      "type": "boolean"\n    },\n    "include_tables": {\n      "title": "Include Tables",\n      "description": "Whether tables should be ingested.",\n      "default": true,\n      "type": "boolean"\n    },\n    "profiling": {\n      "title": "Profiling",\n      "default": {\n        "enabled": false,\n        "limit": null,\n        "offset": null,\n        "report_dropped_profiles": false,\n        "turn_off_expensive_profiling_metrics": false,\n        "profile_table_level_only": false,\n        "include_field_null_count": true,\n        "include_field_min_value": true,\n        "include_field_max_value": true,\n        "include_field_mean_value": true,\n        "include_field_median_value": true,\n        "include_field_stddev_value": true,\n        "include_field_quantiles": false,\n        "include_field_distinct_value_frequencies": false,\n        "include_field_histogram": false,\n        "include_field_sample_values": true,\n        "max_number_of_fields_to_profile": null,\n        "profile_if_updated_since_days": 1,\n        "profile_table_size_limit": 1,\n        "profile_table_row_limit": 50000,\n        "max_workers": 10,\n        "query_combiner_enabled": true,\n        "catch_exceptions": true,\n        "partition_profiling_enabled": true,\n        "bigquery_temp_table_schema": null,\n        "partition_datetime": null\n      },\n      "allOf": [\n        {\n          "$ref": "#/definitions/GEProfilingConfig"\n        }\n      ]\n    },\n    "username": {\n      "title": "Username",\n      "description": "username",\n      "type": "string"\n    },\n    "password": {\n      "title": "Password",\n      "description": "password",\n      "type": "string",\n      "writeOnly": true,\n      "format": "password"\n    },\n    "host_port": {\n      "title": "Host Port",\n      "description": "host URL",\n      "type": "string"\n    },\n    "database": {\n      "title": "Database",\n      "description": "database (catalog)",\n      "type": "string"\n    },\n    "database_alias": {\n      "title": "Database Alias",\n      "description": "Alias to apply to database when ingesting.",\n      "type": "string"\n    },\n    "sqlalchemy_uri": {\n      "title": "Sqlalchemy Uri",\n      "description": "URI of database to connect to. See https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls. Takes precedence over other connection parameters.",\n      "type": "string"\n    },\n    "default_schema": {\n      "title": "Default Schema",\n      "description": "The default schema to use if the sql parser fails to parse the schema with `sql_based` lineage collector",\n      "default": "public",\n      "type": "string"\n    },\n    "include_table_lineage": {\n      "title": "Include Table Lineage",\n      "description": "Whether table lineage should be ingested.",\n      "default": true,\n      "type": "boolean"\n    },\n    "include_copy_lineage": {\n      "title": "Include Copy Lineage",\n      "description": "Whether lineage should be collected from copy commands",\n      "default": true,\n      "type": "boolean"\n    },\n    "capture_lineage_query_parser_failures": {\n      "title": "Capture Lineage Query Parser Failures",\n      "description": "Whether to capture lineage query parser errors with dataset properties for debuggings",\n      "default": false,\n      "type": "boolean"\n    },\n    "table_lineage_mode": {\n      "description": "Which table lineage collector mode to use. Available modes are: [stl_scan_based, sql_based, mixed]",\n      "default": "stl_scan_based",\n      "allOf": [\n        {\n          "$ref": "#/definitions/LineageMode"\n        }\n      ]\n    }\n  },\n  "required": [\n    "host_port"\n  ],\n  "additionalProperties": false,\n  "definitions": {\n    "PathSpec": {\n      "title": "PathSpec",\n      "type": "object",\n      "properties": {\n        "include": {\n          "title": "Include",\n          "description": "Path to table (s3 or local file system). Name variable {table} is used to mark the folder with dataset. In absence of {table}, file level dataset will be created. Check below examples for more details.",\n          "type": "string"\n        },\n        "exclude": {\n          "title": "Exclude",\n          "description": "list of paths in glob pattern which will be excluded while scanning for the datasets",\n          "type": "array",\n          "items": {\n            "type": "string"\n          }\n        },\n        "file_types": {\n          "title": "File Types",\n          "description": "Files with extenstions specified here (subset of default value) only will be scanned to create dataset. Other files will be omitted.",\n          "default": [\n            "csv",\n            "tsv",\n            "json",\n            "parquet",\n            "avro"\n          ],\n          "type": "array",\n          "items": {\n            "type": "string"\n          }\n        },\n        "default_extension": {\n          "title": "Default Extension",\n          "description": "For files without extension it will assume the specified file type. If it is not set the files without extensions will be skipped.",\n          "type": "string"\n        },\n        "table_name": {\n          "title": "Table Name",\n          "description": "Display name of the dataset.Combination of named variables from include path and strings",\n          "type": "string"\n        },\n        "enable_compression": {\n          "title": "Enable Compression",\n          "description": "Enable or disable processing compressed files. Currently .gz and .bz files are supported.",\n          "default": true,\n          "type": "boolean"\n        },\n        "sample_files": {\n          "title": "Sample Files",\n          "description": "Not listing all the files but only taking a handful amount of sample file to infer the schema. File count and file size calculation will be disabled. This can affect performance significantly if enabled",\n          "default": true,\n          "type": "boolean"\n        }\n      },\n      "required": [\n        "include"\n      ],\n      "additionalProperties": false\n    },\n    "S3LineageProviderConfig": {\n      "title": "S3LineageProviderConfig",\n      "description": "Any source that produces s3 lineage from/to Datasets should inherit this class.",\n      "type": "object",\n      "properties": {\n        "path_specs": {\n          "title": "Path Specs",\n          "description": "List of PathSpec. See below the details about PathSpec",\n          "type": "array",\n          "items": {\n            "$ref": "#/definitions/PathSpec"\n          }\n        }\n      },\n      "required": [\n        "path_specs"\n      ],\n      "additionalProperties": false\n    },\n    "BucketDuration": {\n      "title": "BucketDuration",\n      "description": "An enumeration.",\n      "enum": [\n        "DAY",\n        "HOUR"\n      ],\n      "type": "string"\n    },\n    "DynamicTypedStateProviderConfig": {\n      "title": "DynamicTypedStateProviderConfig",\n      "type": "object",\n      "properties": {\n        "type": {\n          "title": "Type",\n          "description": "The type of the state provider to use. For DataHub use `datahub`",\n          "type": "string"\n        },\n        "config": {\n          "title": "Config",\n          "description": "The configuration required for initializing the state provider. Default: The datahub_api config if set at pipeline level. Otherwise, the default DatahubClientConfig. See the defaults (https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/graph/client.py#L19)."\n        }\n      },\n      "required": [\n        "type"\n      ],\n      "additionalProperties": false\n    },\n    "SQLAlchemyStatefulIngestionConfig": {\n      "title": "SQLAlchemyStatefulIngestionConfig",\n      "description": "Specialization of StatefulStaleMetadataRemovalConfig to adding custom config.\\nThis will be used to override the stateful_ingestion config param of StatefulIngestionConfigBase\\nin the SQLAlchemyConfig.",\n      "type": "object",\n      "properties": {\n        "enabled": {\n          "title": "Enabled",\n          "description": "The type of the ingestion state provider registered with datahub.",\n          "default": false,\n          "type": "boolean"\n        },\n        "max_checkpoint_state_size": {\n          "title": "Max Checkpoint State Size",\n          "description": "The maximum size of the checkpoint state in bytes. Default is 16MB",\n          "default": 16777216,\n          "exclusiveMinimum": 0,\n          "type": "integer"\n        },\n        "state_provider": {\n          "title": "State Provider",\n          "description": "The ingestion state provider configuration.",\n          "allOf": [\n            {\n              "$ref": "#/definitions/DynamicTypedStateProviderConfig"\n            }\n          ]\n        },\n        "ignore_old_state": {\n          "title": "Ignore Old State",\n          "description": "If set to True, ignores the previous checkpoint state.",\n          "default": false,\n          "type": "boolean"\n        },\n        "ignore_new_state": {\n          "title": "Ignore New State",\n          "description": "If set to True, ignores the current checkpoint state.",\n          "default": false,\n          "type": "boolean"\n        },\n        "remove_stale_metadata": {\n          "title": "Remove Stale Metadata",\n          "description": "Soft-deletes the entities of type  in the last successful run but missing in the current run with stateful_ingestion enabled.",\n          "default": true,\n          "type": "boolean"\n        },\n        "fail_safe_threshold": {\n          "title": "Fail Safe Threshold",\n          "description": "Prevents large amount of soft deletes & the state from committing from accidental changes to the source configuration if the relative change percent in entities compared to the previous state is above the \'fail_safe_threshold\'.",\n          "default": 20.0,\n          "minimum": 0.0,\n          "maximum": 100.0,\n          "type": "number"\n        }\n      },\n      "additionalProperties": false\n    },\n    "AllowDenyPattern": {\n      "title": "AllowDenyPattern",\n      "description": "A class to store allow deny regexes",\n      "type": "object",\n      "properties": {\n        "allow": {\n          "title": "Allow",\n          "description": "List of regex patterns to include in ingestion",\n          "default": [\n            ".*"\n          ],\n          "type": "array",\n          "items": {\n            "type": "string"\n          }\n        },\n        "deny": {\n          "title": "Deny",\n          "description": "List of regex patterns to exclude from ingestion.",\n          "default": [],\n          "type": "array",\n          "items": {\n            "type": "string"\n          }\n        },\n        "ignoreCase": {\n          "title": "Ignorecase",\n          "description": "Whether to ignore case sensitivity during pattern matching.",\n          "default": true,\n          "type": "boolean"\n        }\n      },\n      "additionalProperties": false\n    },\n    "GEProfilingConfig": {\n      "title": "GEProfilingConfig",\n      "type": "object",\n      "properties": {\n        "enabled": {\n          "title": "Enabled",\n          "description": "Whether profiling should be done.",\n          "default": false,\n          "type": "boolean"\n        },\n        "limit": {\n          "title": "Limit",\n          "description": "Max number of documents to profile. By default, profiles all documents.",\n          "type": "integer"\n        },\n        "offset": {\n          "title": "Offset",\n          "description": "Offset in documents to profile. By default, uses no offset.",\n          "type": "integer"\n        },\n        "report_dropped_profiles": {\n          "title": "Report Dropped Profiles",\n          "description": "Whether to report datasets or dataset columns which were not profiled. Set to `True` for debugging purposes.",\n          "default": false,\n          "type": "boolean"\n        },\n        "turn_off_expensive_profiling_metrics": {\n          "title": "Turn Off Expensive Profiling Metrics",\n          "description": "Whether to turn off expensive profiling or not. This turns off profiling for quantiles, distinct_value_frequencies, histogram & sample_values. This also limits maximum number of fields being profiled to 10.",\n          "default": false,\n          "type": "boolean"\n        },\n        "profile_table_level_only": {\n          "title": "Profile Table Level Only",\n          "description": "Whether to perform profiling at table-level only, or include column-level profiling as well.",\n          "default": false,\n          "type": "boolean"\n        },\n        "include_field_null_count": {\n          "title": "Include Field Null Count",\n          "description": "Whether to profile for the number of nulls for each column.",\n          "default": true,\n          "type": "boolean"\n        },\n        "include_field_min_value": {\n          "title": "Include Field Min Value",\n          "description": "Whether to profile for the min value of numeric columns.",\n          "default": true,\n          "type": "boolean"\n        },\n        "include_field_max_value": {\n          "title": "Include Field Max Value",\n          "description": "Whether to profile for the max value of numeric columns.",\n          "default": true,\n          "type": "boolean"\n        },\n        "include_field_mean_value": {\n          "title": "Include Field Mean Value",\n          "description": "Whether to profile for the mean value of numeric columns.",\n          "default": true,\n          "type": "boolean"\n        },\n        "include_field_median_value": {\n          "title": "Include Field Median Value",\n          "description": "Whether to profile for the median value of numeric columns.",\n          "default": true,\n          "type": "boolean"\n        },\n        "include_field_stddev_value": {\n          "title": "Include Field Stddev Value",\n          "description": "Whether to profile for the standard deviation of numeric columns.",\n          "default": true,\n          "type": "boolean"\n        },\n        "include_field_quantiles": {\n          "title": "Include Field Quantiles",\n          "description": "Whether to profile for the quantiles of numeric columns.",\n          "default": false,\n          "type": "boolean"\n        },\n        "include_field_distinct_value_frequencies": {\n          "title": "Include Field Distinct Value Frequencies",\n          "description": "Whether to profile for distinct value frequencies.",\n          "default": false,\n          "type": "boolean"\n        },\n        "include_field_histogram": {\n          "title": "Include Field Histogram",\n          "description": "Whether to profile for the histogram for numeric fields.",\n          "default": false,\n          "type": "boolean"\n        },\n        "include_field_sample_values": {\n          "title": "Include Field Sample Values",\n          "description": "Whether to profile for the sample values for all columns.",\n          "default": true,\n          "type": "boolean"\n        },\n        "max_number_of_fields_to_profile": {\n          "title": "Max Number Of Fields To Profile",\n          "description": "A positive integer that specifies the maximum number of columns to profile for any table. `None` implies all columns. The cost of profiling goes up significantly as the number of columns to profile goes up.",\n          "exclusiveMinimum": 0,\n          "type": "integer"\n        },\n        "profile_if_updated_since_days": {\n          "title": "Profile If Updated Since Days",\n          "description": "Profile table only if it has been updated since these many number of days. If set to `null`, no constraint of last modified time for tables to profile. Supported only in `snowflake`, `snowflake-beta` and `BigQuery`.",\n          "default": 1,\n          "exclusiveMinimum": 0,\n          "type": "number"\n        },\n        "profile_table_size_limit": {\n          "title": "Profile Table Size Limit",\n          "description": "Profile tables only if their size is less then specified GBs. If set to `null`, no limit on the size of tables to profile. Supported only in `snowflake-beta` and `BigQuery`",\n          "default": 1,\n          "type": "integer"\n        },\n        "profile_table_row_limit": {\n          "title": "Profile Table Row Limit",\n          "description": "Profile tables only if their row count is less then specified count. If set to `null`, no limit on the row count of tables to profile. Supported only in `snowflake-beta` and `BigQuery`",\n          "default": 50000,\n          "type": "integer"\n        },\n        "max_workers": {\n          "title": "Max Workers",\n          "description": "Number of worker threads to use for profiling. Set to 1 to disable.",\n          "default": 10,\n          "type": "integer"\n        },\n        "query_combiner_enabled": {\n          "title": "Query Combiner Enabled",\n          "description": "*This feature is still experimental and can be disabled if it causes issues.* Reduces the total number of queries issued and speeds up profiling by dynamically combining SQL queries where possible.",\n          "default": true,\n          "type": "boolean"\n        },\n        "catch_exceptions": {\n          "title": "Catch Exceptions",\n          "default": true,\n          "type": "boolean"\n        },\n        "partition_profiling_enabled": {\n          "title": "Partition Profiling Enabled",\n          "default": true,\n          "type": "boolean"\n        },\n        "bigquery_temp_table_schema": {\n          "title": "Bigquery Temp Table Schema",\n          "description": "On bigquery for profiling partitioned tables needs to create temporary views. You have to define a dataset where these will be created. Views will be cleaned up after profiler runs. (Great expectation tech details about this (https://legacy.docs.greatexpectations.io/en/0.9.0/reference/integrations/bigquery.html#custom-queries-with-sql-datasource).",\n          "type": "string"\n        },\n        "partition_datetime": {\n          "title": "Partition Datetime",\n          "description": "For partitioned datasets profile only the partition which matches the datetime or profile the latest one if not set. Only Bigquery supports this.",\n          "type": "string",\n          "format": "date-time"\n        }\n      },\n      "additionalProperties": false\n    },\n    "LineageMode": {\n      "title": "LineageMode",\n      "description": "An enumeration.",\n      "enum": [\n        "sql_based",\n        "stl_scan_based",\n        "mixed"\n      ]\n    }\n  }\n}\n')))),(0,l.kt)("h3",{id:"code-coordinates"},"Code Coordinates"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Class Name: ",(0,l.kt)("inlineCode",{parentName:"li"},"datahub.ingestion.source.sql.redshift.RedshiftSource")),(0,l.kt)("li",{parentName:"ul"},"Browse on ",(0,l.kt)("a",{parentName:"li",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/sql/redshift.py"},"GitHub"))),(0,l.kt)("h2",{id:"module-redshift-usage"},"Module ",(0,l.kt)("inlineCode",{parentName:"h2"},"redshift-usage")),(0,l.kt)("p",null,(0,l.kt)("img",{parentName:"p",src:"https://img.shields.io/badge/support%20status-certified-brightgreen",alt:"Certified"})),(0,l.kt)("h3",{id:"important-capabilities-1"},"Important Capabilities"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Capability"),(0,l.kt)("th",{parentName:"tr",align:null},"Status"),(0,l.kt)("th",{parentName:"tr",align:null},"Notes"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("a",{parentName:"td",href:"/docs/platform-instances"},"Platform Instance")),(0,l.kt)("td",{parentName:"tr",align:null},"\u2705"),(0,l.kt)("td",{parentName:"tr",align:null},"Enabled by default")))),(0,l.kt)("p",null,"This plugin extracts usage statistics for datasets in Amazon Redshift."),(0,l.kt)("p",null,"Note: Usage information is computed by querying the following system tables -"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"stl_scan"),(0,l.kt)("li",{parentName:"ol"},"svv_table_info"),(0,l.kt)("li",{parentName:"ol"},"stl_query"),(0,l.kt)("li",{parentName:"ol"},"svl_user_info")),(0,l.kt)("p",null,"To grant access this plugin for all system tables, please alter your datahub Redshift user the following way:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER USER datahub_user WITH SYSLOG ACCESS UNRESTRICTED;\n")),(0,l.kt)("p",null,"This plugin has the below functionalities -"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"For a specific dataset this plugin ingests the following statistics -",(0,l.kt)("ol",{parentName:"li"},(0,l.kt)("li",{parentName:"ol"},"top n queries."),(0,l.kt)("li",{parentName:"ol"},"top users."),(0,l.kt)("li",{parentName:"ol"},"usage of each column in the dataset."))),(0,l.kt)("li",{parentName:"ol"},"Aggregation of these statistics into buckets, by day or hour granularity.")),(0,l.kt)("admonition",{type:"note"},(0,l.kt)("p",{parentName:"admonition"},"This source only does usage statistics. To get the tables, views, and schemas in your Redshift warehouse, ingest using the ",(0,l.kt)("inlineCode",{parentName:"p"},"redshift")," source described above.")),(0,l.kt)("admonition",{type:"note"},(0,l.kt)("p",{parentName:"admonition"},"Redshift system tables have some latency in getting data from queries. In addition, these tables only maintain logs for 2-5 days. You can find more information from the official documentation ",(0,l.kt)("a",{parentName:"p",href:"https://aws.amazon.com/premiumsupport/knowledge-center/logs-redshift-database-cluster/"},"here"),".")),(0,l.kt)("h3",{id:"cli-based-ingestion-1"},"CLI based Ingestion"),(0,l.kt)("h4",{id:"install-the-plugin-1"},"Install the Plugin"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell"},"pip install 'acryl-datahub[redshift-usage]'\n")),(0,l.kt)("h3",{id:"starter-recipe-1"},"Starter Recipe"),(0,l.kt)("p",null,"Check out the following recipe to get started with ingestion! See ",(0,l.kt)("a",{parentName:"p",href:"#config-details"},"below")," for full configuration options."),(0,l.kt)("p",null,"For general pointers on writing and running a recipe, see our ",(0,l.kt)("a",{parentName:"p",href:"/docs/metadata-ingestion#recipes"},"main recipe guide"),"."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},'source:\n  type: redshift-usage\n  config:\n    # Coordinates\n    host_port: db_host:port\n    database: dev\n    email_domain: acryl.io\n\n    # Credentials\n    username: username\n    password: "password"\n\nsink:\n# sink configs\n')),(0,l.kt)("h3",{id:"config-details-1"},"Config Details"),(0,l.kt)(r.Z,{mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"options",label:"Options",default:!0,mdxType:"TabItem"},(0,l.kt)("p",null,"Note that a ",(0,l.kt)("inlineCode",{parentName:"p"},".")," is used to denote nested fields in the YAML recipe."),(0,l.kt)("details",{open:!0},(0,l.kt)("summary",null,"View All Configuration Options"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Field"),(0,l.kt)("th",{parentName:"tr",align:null},"Required"),(0,l.kt)("th",{parentName:"tr",align:null},"Type"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"),(0,l.kt)("th",{parentName:"tr",align:null},"Default"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"env"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"The environment that all assets produced by this connector belong to"),(0,l.kt)("td",{parentName:"tr",align:null},"PROD")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"bucket_duration"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"enum(BucketDuration)"),(0,l.kt)("td",{parentName:"tr",align:null},"Size of the time window to aggregate usage stats.. Allowed symbols are DAY, HOUR"),(0,l.kt)("td",{parentName:"tr",align:null},"DAY")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"end_time"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"Latest date of usage to consider. Default: Current time in UTC"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"start_time"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"Earliest date of usage to consider. Default: Last full day in UTC (or hour, depending on ",(0,l.kt)("inlineCode",{parentName:"td"},"bucket_duration"),")"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"top_n_queries"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"Number of top queries to save to each table."),(0,l.kt)("td",{parentName:"tr",align:null},"10")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"include_operational_stats"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to display operational stats."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"include_read_operational_stats"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to report read operational stats. Experimental."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"format_sql_queries"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to format sql queries"),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"include_top_n_queries"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to ingest the top_n_queries."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"platform_instance_map"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Dict","[str,string]"),(0,l.kt)("td",{parentName:"tr",align:null},"A holder for platform -> platform_instance mappings to generate correct dataset urns"),(0,l.kt)("td",{parentName:"tr",align:null})),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"platform"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"The platform that this source connects to"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"platform_instance"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"The instance of the platform that all assets produced by this recipe belong to"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"options"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Dict"),(0,l.kt)("td",{parentName:"tr",align:null},"Any options specified here will be passed to SQLAlchemy's create_engine as kwargs.See ",(0,l.kt)("a",{parentName:"td",href:"https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine"},"https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine")," for details."),(0,l.kt)("td",{parentName:"tr",align:null},"{}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"include_views"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether views should be ingested."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"include_tables"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether tables should be ingested."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"username"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"username"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"password"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"password"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"host_port"),(0,l.kt)("td",{parentName:"tr",align:null},"\u2705"),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"host URL"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"database"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"database (catalog)"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"database_alias"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"Alias to apply to database when ingesting."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"sqlalchemy_uri"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"URI of database to connect to. See ",(0,l.kt)("a",{parentName:"td",href:"https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls"},"https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls"),". Takes precedence over other connection parameters."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"default_schema"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"The default schema to use if the sql parser fails to parse the schema with ",(0,l.kt)("inlineCode",{parentName:"td"},"sql_based")," lineage collector"),(0,l.kt)("td",{parentName:"tr",align:null},"public")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"include_table_lineage"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether table lineage should be ingested."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"include_copy_lineage"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether lineage should be collected from copy commands"),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"capture_lineage_query_parser_failures"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to capture lineage query parser errors with dataset properties for debuggings"),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"table_lineage_mode"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"enum(LineageMode)"),(0,l.kt)("td",{parentName:"tr",align:null},"Which table lineage collector mode to use. Available modes are: ","[stl_scan_based, sql_based, mixed]"),(0,l.kt)("td",{parentName:"tr",align:null},"stl_scan_based")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"email_domain"),(0,l.kt)("td",{parentName:"tr",align:null},"\u2705"),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"Email domain of your organisation so users can be displayed on UI appropriately."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"user_email_pattern"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"AllowDenyPattern (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null},"regex patterns for user emails to filter in usage."),(0,l.kt)("td",{parentName:"tr",align:null},"{'allow': ","['.*']",", 'deny': [], 'ignoreCase': True}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"user_email_pattern.allow"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to include in ingestion"),(0,l.kt)("td",{parentName:"tr",align:null},"['.*']")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"user_email_pattern.deny"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to exclude from ingestion."),(0,l.kt)("td",{parentName:"tr",align:null},"[]")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"user_email_pattern.ignoreCase"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to ignore case sensitivity during pattern matching."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"s3_lineage_config"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"S3LineageProviderConfig (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null},"Common config for S3 lineage generation"),(0,l.kt)("td",{parentName:"tr",align:null})),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"s3_lineage_config.path_specs"),(0,l.kt)("td",{parentName:"tr",align:null},"\u2753 (required if s3_lineage_config is set)"),(0,l.kt)("td",{parentName:"tr",align:null},"Array of object"),(0,l.kt)("td",{parentName:"tr",align:null},"List of PathSpec. See below the details about PathSpec"),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"SQLAlchemyStatefulIngestionConfig (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null})),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.enabled"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"The type of the ingestion state provider registered with datahub."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.max_checkpoint_state_size"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"The maximum size of the checkpoint state in bytes. Default is 16MB"),(0,l.kt)("td",{parentName:"tr",align:null},"16777216")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.state_provider"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"DynamicTypedStateProviderConfig (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null},"The ingestion state provider configuration."),(0,l.kt)("td",{parentName:"tr",align:null})),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.state_provider.type"),(0,l.kt)("td",{parentName:"tr",align:null},"\u2753 (required if stateful_ingestion.state_provider is set)"),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"The type of the state provider to use. For DataHub use ",(0,l.kt)("inlineCode",{parentName:"td"},"datahub")),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.state_provider.config"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Generic dict"),(0,l.kt)("td",{parentName:"tr",align:null},"The configuration required for initializing the state provider. Default: The datahub_api config if set at pipeline level. Otherwise, the default DatahubClientConfig. See the defaults (",(0,l.kt)("a",{parentName:"td",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/graph/client.py#L19"},"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/graph/client.py#L19"),")."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.ignore_old_state"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"If set to True, ignores the previous checkpoint state."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.ignore_new_state"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"If set to True, ignores the current checkpoint state."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.remove_stale_metadata"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Soft-deletes the entities of type  in the last successful run but missing in the current run with stateful_ingestion enabled."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"stateful_ingestion.fail_safe_threshold"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"number"),(0,l.kt)("td",{parentName:"tr",align:null},"Prevents large amount of soft deletes & the state from committing from accidental changes to the source configuration if the relative change percent in entities compared to the previous state is above the 'fail_safe_threshold'."),(0,l.kt)("td",{parentName:"tr",align:null},"20.0")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"schema_pattern"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"AllowDenyPattern (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"{'allow': ","['.*']",", 'deny': ","['information_schema']",", 'ignoreCase': True}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"schema_pattern.allow"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to include in ingestion"),(0,l.kt)("td",{parentName:"tr",align:null},"['.*']")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"schema_pattern.deny"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to exclude from ingestion."),(0,l.kt)("td",{parentName:"tr",align:null},"[]")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"schema_pattern.ignoreCase"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to ignore case sensitivity during pattern matching."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"table_pattern"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"AllowDenyPattern (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null},"Regex patterns for tables to filter in ingestion. Specify regex to match the entire table name in database.schema.table format. e.g. to match all tables starting with customer in Customer database and public schema, use the regex 'Customer.public.customer.*'"),(0,l.kt)("td",{parentName:"tr",align:null},"{'allow': ","['.*']",", 'deny': [], 'ignoreCase': True}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"table_pattern.allow"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to include in ingestion"),(0,l.kt)("td",{parentName:"tr",align:null},"['.*']")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"table_pattern.deny"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to exclude from ingestion."),(0,l.kt)("td",{parentName:"tr",align:null},"[]")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"table_pattern.ignoreCase"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to ignore case sensitivity during pattern matching."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"view_pattern"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"AllowDenyPattern (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null},"Regex patterns for views to filter in ingestion. Note: Defaults to table_pattern if not specified. Specify regex to match the entire view name in database.schema.view format. e.g. to match all views starting with customer in Customer database and public schema, use the regex 'Customer.public.customer.*'"),(0,l.kt)("td",{parentName:"tr",align:null},"{'allow': ","['.*']",", 'deny': [], 'ignoreCase': True}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"view_pattern.allow"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to include in ingestion"),(0,l.kt)("td",{parentName:"tr",align:null},"['.*']")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"view_pattern.deny"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to exclude from ingestion."),(0,l.kt)("td",{parentName:"tr",align:null},"[]")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"view_pattern.ignoreCase"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to ignore case sensitivity during pattern matching."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profile_pattern"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"AllowDenyPattern (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null},"Regex patterns to filter tables for profiling during ingestion. Allowed by the ",(0,l.kt)("inlineCode",{parentName:"td"},"table_pattern"),"."),(0,l.kt)("td",{parentName:"tr",align:null},"{'allow': ","['.*']",", 'deny': [], 'ignoreCase': True}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profile_pattern.allow"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to include in ingestion"),(0,l.kt)("td",{parentName:"tr",align:null},"['.*']")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profile_pattern.deny"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to exclude from ingestion."),(0,l.kt)("td",{parentName:"tr",align:null},"[]")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profile_pattern.ignoreCase"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to ignore case sensitivity during pattern matching."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"domain"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Dict","[str, AllowDenyPattern]"),(0,l.kt)("td",{parentName:"tr",align:null},"Attach domains to databases, schemas or tables during ingestion using regex patterns. Domain key can be a guid like ",(0,l.kt)("em",{parentName:"td"},"urn:li:domain:ec428203-ce86-4db3-985d-5a8ee6df32ba"),' or a string like "Marketing".) If you provide strings, then datahub will attempt to resolve this name to a guid, and will error out if this fails. There can be multiple domain keys specified.'),(0,l.kt)("td",{parentName:"tr",align:null},"{}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"domain.",(0,l.kt)("inlineCode",{parentName:"td"},"key"),".allow"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to include in ingestion"),(0,l.kt)("td",{parentName:"tr",align:null},"['.*']")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"domain.",(0,l.kt)("inlineCode",{parentName:"td"},"key"),".deny"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"Array of string"),(0,l.kt)("td",{parentName:"tr",align:null},"List of regex patterns to exclude from ingestion."),(0,l.kt)("td",{parentName:"tr",align:null},"[]")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"domain.",(0,l.kt)("inlineCode",{parentName:"td"},"key"),".ignoreCase"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to ignore case sensitivity during pattern matching."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"GEProfilingConfig (see below for fields)"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"{'enabled': False, 'limit': None, 'offset': None, 'report_dropped_profiles': False, 'turn_off_expensive_profiling_metrics': False, 'profile_table_level_only': False, 'include_field_null_count': True, 'include_field_min_value': True, 'include_field_max_value': True, 'include_field_mean_value': True, 'include_field_median_value': True, 'include_field_stddev_value': True, 'include_field_quantiles': False, 'include_field_distinct_value_frequencies': False, 'include_field_histogram': False, 'include_field_sample_values': True, 'max_number_of_fields_to_profile': None, 'profile_if_updated_since_days': 1, 'profile_table_size_limit': 1, 'profile_table_row_limit': 50000, 'max_workers': 10, 'query_combiner_enabled': True, 'catch_exceptions': True, 'partition_profiling_enabled': True, 'bigquery_temp_table_schema': None, 'partition_datetime': None}")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.enabled"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether profiling should be done."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.limit"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"Max number of documents to profile. By default, profiles all documents."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.offset"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"Offset in documents to profile. By default, uses no offset."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.report_dropped_profiles"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to report datasets or dataset columns which were not profiled. Set to ",(0,l.kt)("inlineCode",{parentName:"td"},"True")," for debugging purposes."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.turn_off_expensive_profiling_metrics"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to turn off expensive profiling or not. This turns off profiling for quantiles, distinct_value_frequencies, histogram & sample_values. This also limits maximum number of fields being profiled to 10."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.profile_table_level_only"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to perform profiling at table-level only, or include column-level profiling as well."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_null_count"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the number of nulls for each column."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_min_value"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the min value of numeric columns."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_max_value"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the max value of numeric columns."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_mean_value"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the mean value of numeric columns."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_median_value"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the median value of numeric columns."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_stddev_value"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the standard deviation of numeric columns."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_quantiles"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the quantiles of numeric columns."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_distinct_value_frequencies"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for distinct value frequencies."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_histogram"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the histogram for numeric fields."),(0,l.kt)("td",{parentName:"tr",align:null},"False")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.include_field_sample_values"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},"Whether to profile for the sample values for all columns."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.max_number_of_fields_to_profile"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"A positive integer that specifies the maximum number of columns to profile for any table. ",(0,l.kt)("inlineCode",{parentName:"td"},"None")," implies all columns. The cost of profiling goes up significantly as the number of columns to profile goes up."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.profile_if_updated_since_days"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"number"),(0,l.kt)("td",{parentName:"tr",align:null},"Profile table only if it has been updated since these many number of days. If set to ",(0,l.kt)("inlineCode",{parentName:"td"},"null"),", no constraint of last modified time for tables to profile. Supported only in ",(0,l.kt)("inlineCode",{parentName:"td"},"snowflake"),", ",(0,l.kt)("inlineCode",{parentName:"td"},"snowflake-beta")," and ",(0,l.kt)("inlineCode",{parentName:"td"},"BigQuery"),"."),(0,l.kt)("td",{parentName:"tr",align:null},"1")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.profile_table_size_limit"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"Profile tables only if their size is less then specified GBs. If set to ",(0,l.kt)("inlineCode",{parentName:"td"},"null"),", no limit on the size of tables to profile. Supported only in ",(0,l.kt)("inlineCode",{parentName:"td"},"snowflake-beta")," and ",(0,l.kt)("inlineCode",{parentName:"td"},"BigQuery")),(0,l.kt)("td",{parentName:"tr",align:null},"1")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.profile_table_row_limit"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"Profile tables only if their row count is less then specified count. If set to ",(0,l.kt)("inlineCode",{parentName:"td"},"null"),", no limit on the row count of tables to profile. Supported only in ",(0,l.kt)("inlineCode",{parentName:"td"},"snowflake-beta")," and ",(0,l.kt)("inlineCode",{parentName:"td"},"BigQuery")),(0,l.kt)("td",{parentName:"tr",align:null},"50000")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.max_workers"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"integer"),(0,l.kt)("td",{parentName:"tr",align:null},"Number of worker threads to use for profiling. Set to 1 to disable."),(0,l.kt)("td",{parentName:"tr",align:null},"10")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.query_combiner_enabled"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null},(0,l.kt)("em",{parentName:"td"},"This feature is still experimental and can be disabled if it causes issues.")," Reduces the total number of queries issued and speeds up profiling by dynamically combining SQL queries where possible."),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.catch_exceptions"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.partition_profiling_enabled"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"boolean"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"True")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.bigquery_temp_table_schema"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"On bigquery for profiling partitioned tables needs to create temporary views. You have to define a dataset where these will be created. Views will be cleaned up after profiler runs. (Great expectation tech details about this (",(0,l.kt)("a",{parentName:"td",href:"https://legacy.docs.greatexpectations.io/en/0.9.0/reference/integrations/bigquery.html#custom-queries-with-sql-datasource"},"https://legacy.docs.greatexpectations.io/en/0.9.0/reference/integrations/bigquery.html#custom-queries-with-sql-datasource"),")."),(0,l.kt)("td",{parentName:"tr",align:null},"None")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"profiling.partition_datetime"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null},"string"),(0,l.kt)("td",{parentName:"tr",align:null},"For partitioned datasets profile only the partition which matches the datetime or profile the latest one if not set. Only Bigquery supports this."),(0,l.kt)("td",{parentName:"tr",align:null},"None")))))),(0,l.kt)(i.Z,{value:"schema",label:"Schema",mdxType:"TabItem"},(0,l.kt)("p",null,"The ",(0,l.kt)("a",{parentName:"p",href:"https://json-schema.org/"},"JSONSchema")," for this configuration is inlined below."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-javascript"},'{\n  "title": "RedshiftUsageConfig",\n  "description": "Base configuration class for stateful ingestion for source configs to inherit from.",\n  "type": "object",\n  "properties": {\n    "env": {\n      "title": "Env",\n      "description": "The environment that all assets produced by this connector belong to",\n      "default": "PROD",\n      "type": "string"\n    },\n    "bucket_duration": {\n      "description": "Size of the time window to aggregate usage stats.",\n      "default": "DAY",\n      "allOf": [\n        {\n          "$ref": "#/definitions/BucketDuration"\n        }\n      ]\n    },\n    "end_time": {\n      "title": "End Time",\n      "description": "Latest date of usage to consider. Default: Current time in UTC",\n      "type": "string",\n      "format": "date-time"\n    },\n    "start_time": {\n      "title": "Start Time",\n      "description": "Earliest date of usage to consider. Default: Last full day in UTC (or hour, depending on `bucket_duration`)",\n      "type": "string",\n      "format": "date-time"\n    },\n    "top_n_queries": {\n      "title": "Top N Queries",\n      "description": "Number of top queries to save to each table.",\n      "default": 10,\n      "exclusiveMinimum": 0,\n      "type": "integer"\n    },\n    "user_email_pattern": {\n      "title": "User Email Pattern",\n      "description": "regex patterns for user emails to filter in usage.",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "allOf": [\n        {\n          "$ref": "#/definitions/AllowDenyPattern"\n        }\n      ]\n    },\n    "include_operational_stats": {\n      "title": "Include Operational Stats",\n      "description": "Whether to display operational stats.",\n      "default": true,\n      "type": "boolean"\n    },\n    "include_read_operational_stats": {\n      "title": "Include Read Operational Stats",\n      "description": "Whether to report read operational stats. Experimental.",\n      "default": false,\n      "type": "boolean"\n    },\n    "format_sql_queries": {\n      "title": "Format Sql Queries",\n      "description": "Whether to format sql queries",\n      "default": false,\n      "type": "boolean"\n    },\n    "include_top_n_queries": {\n      "title": "Include Top N Queries",\n      "description": "Whether to ingest the top_n_queries.",\n      "default": true,\n      "type": "boolean"\n    },\n    "s3_lineage_config": {\n      "title": "S3 Lineage Config",\n      "description": "Common config for S3 lineage generation",\n      "allOf": [\n        {\n          "$ref": "#/definitions/S3LineageProviderConfig"\n        }\n      ]\n    },\n    "platform_instance_map": {\n      "title": "Platform Instance Map",\n      "description": "A holder for platform -> platform_instance mappings to generate correct dataset urns",\n      "type": "object",\n      "additionalProperties": {\n        "type": "string"\n      }\n    },\n    "platform": {\n      "title": "Platform",\n      "description": "The platform that this source connects to",\n      "type": "string"\n    },\n    "platform_instance": {\n      "title": "Platform Instance",\n      "description": "The instance of the platform that all assets produced by this recipe belong to",\n      "type": "string"\n    },\n    "stateful_ingestion": {\n      "$ref": "#/definitions/SQLAlchemyStatefulIngestionConfig"\n    },\n    "options": {\n      "title": "Options",\n      "description": "Any options specified here will be passed to SQLAlchemy\'s create_engine as kwargs.See https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine for details.",\n      "default": {},\n      "type": "object"\n    },\n    "schema_pattern": {\n      "title": "Schema Pattern",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [\n          "information_schema"\n        ],\n        "ignoreCase": true\n      },\n      "allOf": [\n        {\n          "$ref": "#/definitions/AllowDenyPattern"\n        }\n      ]\n    },\n    "table_pattern": {\n      "title": "Table Pattern",\n      "description": "Regex patterns for tables to filter in ingestion. Specify regex to match the entire table name in database.schema.table format. e.g. to match all tables starting with customer in Customer database and public schema, use the regex \'Customer.public.customer.*\'",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "allOf": [\n        {\n          "$ref": "#/definitions/AllowDenyPattern"\n        }\n      ]\n    },\n    "view_pattern": {\n      "title": "View Pattern",\n      "description": "Regex patterns for views to filter in ingestion. Note: Defaults to table_pattern if not specified. Specify regex to match the entire view name in database.schema.view format. e.g. to match all views starting with customer in Customer database and public schema, use the regex \'Customer.public.customer.*\'",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "allOf": [\n        {\n          "$ref": "#/definitions/AllowDenyPattern"\n        }\n      ]\n    },\n    "profile_pattern": {\n      "title": "Profile Pattern",\n      "description": "Regex patterns to filter tables for profiling during ingestion. Allowed by the `table_pattern`.",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "allOf": [\n        {\n          "$ref": "#/definitions/AllowDenyPattern"\n        }\n      ]\n    },\n    "domain": {\n      "title": "Domain",\n      "description": "Attach domains to databases, schemas or tables during ingestion using regex patterns. Domain key can be a guid like *urn:li:domain:ec428203-ce86-4db3-985d-5a8ee6df32ba* or a string like \\"Marketing\\".) If you provide strings, then datahub will attempt to resolve this name to a guid, and will error out if this fails. There can be multiple domain keys specified.",\n      "default": {},\n      "type": "object",\n      "additionalProperties": {\n        "$ref": "#/definitions/AllowDenyPattern"\n      }\n    },\n    "include_views": {\n      "title": "Include Views",\n      "description": "Whether views should be ingested.",\n      "default": true,\n      "type": "boolean"\n    },\n    "include_tables": {\n      "title": "Include Tables",\n      "description": "Whether tables should be ingested.",\n      "default": true,\n      "type": "boolean"\n    },\n    "profiling": {\n      "title": "Profiling",\n      "default": {\n        "enabled": false,\n        "limit": null,\n        "offset": null,\n        "report_dropped_profiles": false,\n        "turn_off_expensive_profiling_metrics": false,\n        "profile_table_level_only": false,\n        "include_field_null_count": true,\n        "include_field_min_value": true,\n        "include_field_max_value": true,\n        "include_field_mean_value": true,\n        "include_field_median_value": true,\n        "include_field_stddev_value": true,\n        "include_field_quantiles": false,\n        "include_field_distinct_value_frequencies": false,\n        "include_field_histogram": false,\n        "include_field_sample_values": true,\n        "max_number_of_fields_to_profile": null,\n        "profile_if_updated_since_days": 1,\n        "profile_table_size_limit": 1,\n        "profile_table_row_limit": 50000,\n        "max_workers": 10,\n        "query_combiner_enabled": true,\n        "catch_exceptions": true,\n        "partition_profiling_enabled": true,\n        "bigquery_temp_table_schema": null,\n        "partition_datetime": null\n      },\n      "allOf": [\n        {\n          "$ref": "#/definitions/GEProfilingConfig"\n        }\n      ]\n    },\n    "username": {\n      "title": "Username",\n      "description": "username",\n      "type": "string"\n    },\n    "password": {\n      "title": "Password",\n      "description": "password",\n      "type": "string",\n      "writeOnly": true,\n      "format": "password"\n    },\n    "host_port": {\n      "title": "Host Port",\n      "description": "host URL",\n      "type": "string"\n    },\n    "database": {\n      "title": "Database",\n      "description": "database (catalog)",\n      "type": "string"\n    },\n    "database_alias": {\n      "title": "Database Alias",\n      "description": "Alias to apply to database when ingesting.",\n      "type": "string"\n    },\n    "sqlalchemy_uri": {\n      "title": "Sqlalchemy Uri",\n      "description": "URI of database to connect to. See https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls. Takes precedence over other connection parameters.",\n      "type": "string"\n    },\n    "default_schema": {\n      "title": "Default Schema",\n      "description": "The default schema to use if the sql parser fails to parse the schema with `sql_based` lineage collector",\n      "default": "public",\n      "type": "string"\n    },\n    "include_table_lineage": {\n      "title": "Include Table Lineage",\n      "description": "Whether table lineage should be ingested.",\n      "default": true,\n      "type": "boolean"\n    },\n    "include_copy_lineage": {\n      "title": "Include Copy Lineage",\n      "description": "Whether lineage should be collected from copy commands",\n      "default": true,\n      "type": "boolean"\n    },\n    "capture_lineage_query_parser_failures": {\n      "title": "Capture Lineage Query Parser Failures",\n      "description": "Whether to capture lineage query parser errors with dataset properties for debuggings",\n      "default": false,\n      "type": "boolean"\n    },\n    "table_lineage_mode": {\n      "description": "Which table lineage collector mode to use. Available modes are: [stl_scan_based, sql_based, mixed]",\n      "default": "stl_scan_based",\n      "allOf": [\n        {\n          "$ref": "#/definitions/LineageMode"\n        }\n      ]\n    },\n    "email_domain": {\n      "title": "Email Domain",\n      "description": "Email domain of your organisation so users can be displayed on UI appropriately.",\n      "type": "string"\n    }\n  },\n  "required": [\n    "host_port",\n    "email_domain"\n  ],\n  "additionalProperties": false,\n  "definitions": {\n    "BucketDuration": {\n      "title": "BucketDuration",\n      "description": "An enumeration.",\n      "enum": [\n        "DAY",\n        "HOUR"\n      ],\n      "type": "string"\n    },\n    "AllowDenyPattern": {\n      "title": "AllowDenyPattern",\n      "description": "A class to store allow deny regexes",\n      "type": "object",\n      "properties": {\n        "allow": {\n          "title": "Allow",\n          "description": "List of regex patterns to include in ingestion",\n          "default": [\n            ".*"\n          ],\n          "type": "array",\n          "items": {\n            "type": "string"\n          }\n        },\n        "deny": {\n          "title": "Deny",\n          "description": "List of regex patterns to exclude from ingestion.",\n          "default": [],\n          "type": "array",\n          "items": {\n            "type": "string"\n          }\n        },\n        "ignoreCase": {\n          "title": "Ignorecase",\n          "description": "Whether to ignore case sensitivity during pattern matching.",\n          "default": true,\n          "type": "boolean"\n        }\n      },\n      "additionalProperties": false\n    },\n    "PathSpec": {\n      "title": "PathSpec",\n      "type": "object",\n      "properties": {\n        "include": {\n          "title": "Include",\n          "description": "Path to table (s3 or local file system). Name variable {table} is used to mark the folder with dataset. In absence of {table}, file level dataset will be created. Check below examples for more details.",\n          "type": "string"\n        },\n        "exclude": {\n          "title": "Exclude",\n          "description": "list of paths in glob pattern which will be excluded while scanning for the datasets",\n          "type": "array",\n          "items": {\n            "type": "string"\n          }\n        },\n        "file_types": {\n          "title": "File Types",\n          "description": "Files with extenstions specified here (subset of default value) only will be scanned to create dataset. Other files will be omitted.",\n          "default": [\n            "csv",\n            "tsv",\n            "json",\n            "parquet",\n            "avro"\n          ],\n          "type": "array",\n          "items": {\n            "type": "string"\n          }\n        },\n        "default_extension": {\n          "title": "Default Extension",\n          "description": "For files without extension it will assume the specified file type. If it is not set the files without extensions will be skipped.",\n          "type": "string"\n        },\n        "table_name": {\n          "title": "Table Name",\n          "description": "Display name of the dataset.Combination of named variables from include path and strings",\n          "type": "string"\n        },\n        "enable_compression": {\n          "title": "Enable Compression",\n          "description": "Enable or disable processing compressed files. Currently .gz and .bz files are supported.",\n          "default": true,\n          "type": "boolean"\n        },\n        "sample_files": {\n          "title": "Sample Files",\n          "description": "Not listing all the files but only taking a handful amount of sample file to infer the schema. File count and file size calculation will be disabled. This can affect performance significantly if enabled",\n          "default": true,\n          "type": "boolean"\n        }\n      },\n      "required": [\n        "include"\n      ],\n      "additionalProperties": false\n    },\n    "S3LineageProviderConfig": {\n      "title": "S3LineageProviderConfig",\n      "description": "Any source that produces s3 lineage from/to Datasets should inherit this class.",\n      "type": "object",\n      "properties": {\n        "path_specs": {\n          "title": "Path Specs",\n          "description": "List of PathSpec. See below the details about PathSpec",\n          "type": "array",\n          "items": {\n            "$ref": "#/definitions/PathSpec"\n          }\n        }\n      },\n      "required": [\n        "path_specs"\n      ],\n      "additionalProperties": false\n    },\n    "DynamicTypedStateProviderConfig": {\n      "title": "DynamicTypedStateProviderConfig",\n      "type": "object",\n      "properties": {\n        "type": {\n          "title": "Type",\n          "description": "The type of the state provider to use. For DataHub use `datahub`",\n          "type": "string"\n        },\n        "config": {\n          "title": "Config",\n          "description": "The configuration required for initializing the state provider. Default: The datahub_api config if set at pipeline level. Otherwise, the default DatahubClientConfig. See the defaults (https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/graph/client.py#L19)."\n        }\n      },\n      "required": [\n        "type"\n      ],\n      "additionalProperties": false\n    },\n    "SQLAlchemyStatefulIngestionConfig": {\n      "title": "SQLAlchemyStatefulIngestionConfig",\n      "description": "Specialization of StatefulStaleMetadataRemovalConfig to adding custom config.\\nThis will be used to override the stateful_ingestion config param of StatefulIngestionConfigBase\\nin the SQLAlchemyConfig.",\n      "type": "object",\n      "properties": {\n        "enabled": {\n          "title": "Enabled",\n          "description": "The type of the ingestion state provider registered with datahub.",\n          "default": false,\n          "type": "boolean"\n        },\n        "max_checkpoint_state_size": {\n          "title": "Max Checkpoint State Size",\n          "description": "The maximum size of the checkpoint state in bytes. Default is 16MB",\n          "default": 16777216,\n          "exclusiveMinimum": 0,\n          "type": "integer"\n        },\n        "state_provider": {\n          "title": "State Provider",\n          "description": "The ingestion state provider configuration.",\n          "allOf": [\n            {\n              "$ref": "#/definitions/DynamicTypedStateProviderConfig"\n            }\n          ]\n        },\n        "ignore_old_state": {\n          "title": "Ignore Old State",\n          "description": "If set to True, ignores the previous checkpoint state.",\n          "default": false,\n          "type": "boolean"\n        },\n        "ignore_new_state": {\n          "title": "Ignore New State",\n          "description": "If set to True, ignores the current checkpoint state.",\n          "default": false,\n          "type": "boolean"\n        },\n        "remove_stale_metadata": {\n          "title": "Remove Stale Metadata",\n          "description": "Soft-deletes the entities of type  in the last successful run but missing in the current run with stateful_ingestion enabled.",\n          "default": true,\n          "type": "boolean"\n        },\n        "fail_safe_threshold": {\n          "title": "Fail Safe Threshold",\n          "description": "Prevents large amount of soft deletes & the state from committing from accidental changes to the source configuration if the relative change percent in entities compared to the previous state is above the \'fail_safe_threshold\'.",\n          "default": 20.0,\n          "minimum": 0.0,\n          "maximum": 100.0,\n          "type": "number"\n        }\n      },\n      "additionalProperties": false\n    },\n    "GEProfilingConfig": {\n      "title": "GEProfilingConfig",\n      "type": "object",\n      "properties": {\n        "enabled": {\n          "title": "Enabled",\n          "description": "Whether profiling should be done.",\n          "default": false,\n          "type": "boolean"\n        },\n        "limit": {\n          "title": "Limit",\n          "description": "Max number of documents to profile. By default, profiles all documents.",\n          "type": "integer"\n        },\n        "offset": {\n          "title": "Offset",\n          "description": "Offset in documents to profile. By default, uses no offset.",\n          "type": "integer"\n        },\n        "report_dropped_profiles": {\n          "title": "Report Dropped Profiles",\n          "description": "Whether to report datasets or dataset columns which were not profiled. Set to `True` for debugging purposes.",\n          "default": false,\n          "type": "boolean"\n        },\n        "turn_off_expensive_profiling_metrics": {\n          "title": "Turn Off Expensive Profiling Metrics",\n          "description": "Whether to turn off expensive profiling or not. This turns off profiling for quantiles, distinct_value_frequencies, histogram & sample_values. This also limits maximum number of fields being profiled to 10.",\n          "default": false,\n          "type": "boolean"\n        },\n        "profile_table_level_only": {\n          "title": "Profile Table Level Only",\n          "description": "Whether to perform profiling at table-level only, or include column-level profiling as well.",\n          "default": false,\n          "type": "boolean"\n        },\n        "include_field_null_count": {\n          "title": "Include Field Null Count",\n          "description": "Whether to profile for the number of nulls for each column.",\n          "default": true,\n          "type": "boolean"\n        },\n        "include_field_min_value": {\n          "title": "Include Field Min Value",\n          "description": "Whether to profile for the min value of numeric columns.",\n          "default": true,\n          "type": "boolean"\n        },\n        "include_field_max_value": {\n          "title": "Include Field Max Value",\n          "description": "Whether to profile for the max value of numeric columns.",\n          "default": true,\n          "type": "boolean"\n        },\n        "include_field_mean_value": {\n          "title": "Include Field Mean Value",\n          "description": "Whether to profile for the mean value of numeric columns.",\n          "default": true,\n          "type": "boolean"\n        },\n        "include_field_median_value": {\n          "title": "Include Field Median Value",\n          "description": "Whether to profile for the median value of numeric columns.",\n          "default": true,\n          "type": "boolean"\n        },\n        "include_field_stddev_value": {\n          "title": "Include Field Stddev Value",\n          "description": "Whether to profile for the standard deviation of numeric columns.",\n          "default": true,\n          "type": "boolean"\n        },\n        "include_field_quantiles": {\n          "title": "Include Field Quantiles",\n          "description": "Whether to profile for the quantiles of numeric columns.",\n          "default": false,\n          "type": "boolean"\n        },\n        "include_field_distinct_value_frequencies": {\n          "title": "Include Field Distinct Value Frequencies",\n          "description": "Whether to profile for distinct value frequencies.",\n          "default": false,\n          "type": "boolean"\n        },\n        "include_field_histogram": {\n          "title": "Include Field Histogram",\n          "description": "Whether to profile for the histogram for numeric fields.",\n          "default": false,\n          "type": "boolean"\n        },\n        "include_field_sample_values": {\n          "title": "Include Field Sample Values",\n          "description": "Whether to profile for the sample values for all columns.",\n          "default": true,\n          "type": "boolean"\n        },\n        "max_number_of_fields_to_profile": {\n          "title": "Max Number Of Fields To Profile",\n          "description": "A positive integer that specifies the maximum number of columns to profile for any table. `None` implies all columns. The cost of profiling goes up significantly as the number of columns to profile goes up.",\n          "exclusiveMinimum": 0,\n          "type": "integer"\n        },\n        "profile_if_updated_since_days": {\n          "title": "Profile If Updated Since Days",\n          "description": "Profile table only if it has been updated since these many number of days. If set to `null`, no constraint of last modified time for tables to profile. Supported only in `snowflake`, `snowflake-beta` and `BigQuery`.",\n          "default": 1,\n          "exclusiveMinimum": 0,\n          "type": "number"\n        },\n        "profile_table_size_limit": {\n          "title": "Profile Table Size Limit",\n          "description": "Profile tables only if their size is less then specified GBs. If set to `null`, no limit on the size of tables to profile. Supported only in `snowflake-beta` and `BigQuery`",\n          "default": 1,\n          "type": "integer"\n        },\n        "profile_table_row_limit": {\n          "title": "Profile Table Row Limit",\n          "description": "Profile tables only if their row count is less then specified count. If set to `null`, no limit on the row count of tables to profile. Supported only in `snowflake-beta` and `BigQuery`",\n          "default": 50000,\n          "type": "integer"\n        },\n        "max_workers": {\n          "title": "Max Workers",\n          "description": "Number of worker threads to use for profiling. Set to 1 to disable.",\n          "default": 10,\n          "type": "integer"\n        },\n        "query_combiner_enabled": {\n          "title": "Query Combiner Enabled",\n          "description": "*This feature is still experimental and can be disabled if it causes issues.* Reduces the total number of queries issued and speeds up profiling by dynamically combining SQL queries where possible.",\n          "default": true,\n          "type": "boolean"\n        },\n        "catch_exceptions": {\n          "title": "Catch Exceptions",\n          "default": true,\n          "type": "boolean"\n        },\n        "partition_profiling_enabled": {\n          "title": "Partition Profiling Enabled",\n          "default": true,\n          "type": "boolean"\n        },\n        "bigquery_temp_table_schema": {\n          "title": "Bigquery Temp Table Schema",\n          "description": "On bigquery for profiling partitioned tables needs to create temporary views. You have to define a dataset where these will be created. Views will be cleaned up after profiler runs. (Great expectation tech details about this (https://legacy.docs.greatexpectations.io/en/0.9.0/reference/integrations/bigquery.html#custom-queries-with-sql-datasource).",\n          "type": "string"\n        },\n        "partition_datetime": {\n          "title": "Partition Datetime",\n          "description": "For partitioned datasets profile only the partition which matches the datetime or profile the latest one if not set. Only Bigquery supports this.",\n          "type": "string",\n          "format": "date-time"\n        }\n      },\n      "additionalProperties": false\n    },\n    "LineageMode": {\n      "title": "LineageMode",\n      "description": "An enumeration.",\n      "enum": [\n        "sql_based",\n        "stl_scan_based",\n        "mixed"\n      ]\n    }\n  }\n}\n')))),(0,l.kt)("h3",{id:"code-coordinates-1"},"Code Coordinates"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Class Name: ",(0,l.kt)("inlineCode",{parentName:"li"},"datahub.ingestion.source.usage.redshift_usage.RedshiftUsageSource")),(0,l.kt)("li",{parentName:"ul"},"Browse on ",(0,l.kt)("a",{parentName:"li",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/usage/redshift_usage.py"},"GitHub"))),(0,l.kt)("h2",{id:"questions"},"Questions"),(0,l.kt)("p",null,"If you've got any questions on configuring ingestion for Redshift, feel free to ping us on ",(0,l.kt)("a",{parentName:"p",href:"https://slack.datahubproject.io"},"our Slack")))}g.isMDXComponent=!0}}]);